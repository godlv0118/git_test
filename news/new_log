17-5-31 12:50 发现不能parse问题，原因：ROBOTSTXT_OBEY = true，要遵守robots.txt 的规则。在Scrapy启动后，会在第一时间访问网站的 robots.txt 文件，然后决定该网站的爬取范围。而且在某些情况下我们想要获取的内容恰恰是被 robots.txt 所禁止访问的。所以，某些时候，我们就要将此配置项设置为 False ，拒绝遵守 Robot协议 ，就可以下载网页。
